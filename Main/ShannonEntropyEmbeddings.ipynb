{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score\n",
    "from multiprocessing import Pool\n",
    "import scipy as sc\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns =100\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from Common import preprocessing,evaluation,ner,CosineClassifier as cos\n",
    "classes_map = {'DOC':0, 'ENTER':1, 'ORG':2, 'PRIV':3, 'RANG':4, 'HOST':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..//Data//data.txt', delimiter=';', engine='python',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.array(df.question)\n",
    "questions = preprocessing.preprocess_list(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3,ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(df['class'])\n",
    "y = list(map(lambda x: classes_map[x],classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = OneVsRestClassifier(LogisticRegression(random_state=0,C=10,solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        DOC       0.76      0.77      0.76        65\n",
      "      ENTER       0.58      0.75      0.65        68\n",
      "        ORG       0.75      0.73      0.74       151\n",
      "       PRIV       0.60      0.21      0.32        14\n",
      "       RANG       0.75      0.74      0.75        98\n",
      "       HOST       0.98      0.85      0.91        47\n",
      "\n",
      "avg / total       0.75      0.74      0.74       443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluation.get_classification_report(log_reg,embeddings,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7548604560838927\n",
      "0.7548604560838927\n",
      "0.7548604560838927\n"
     ]
    }
   ],
   "source": [
    "print(evaluation.get_CV_scores(log_reg,X,y,'precision_micro').mean())\n",
    "print(evaluation.get_CV_scores(log_reg,X,y,'recall_micro').mean())\n",
    "print(evaluation.get_CV_scores(log_reg,X,y,'f1_micro').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3916286, 6809500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec([q.split() for q in questions], size=300, window=10,)\n",
    "model.train([q.split() for q in questions],epochs=500,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-827:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\", line 211, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\", line 595, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1)\n",
      "  File \"gensim/models/fasttext_inner.pyx\", line 431, in gensim.models.fasttext_inner.train_batch_cbow\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "Exception in thread Thread-826:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\", line 211, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)\n",
      "  File \"c:\\users\\aleksandr.perevalov\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\", line 595, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1)\n",
      "  File \"gensim/models/fasttext_inner.pyx\", line 431, in gensim.models.fasttext_inner.train_batch_cbow\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FastText([q.split() for q in questions], size=300, window=10,)\n",
    "model.train([q.split() for q in questions],epochs=200,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vecs = []\n",
    "\n",
    "for q in questions:\n",
    "    if len(q) < 1:\n",
    "        doc2vecs.append(np.zeros(300))\n",
    "    else:\n",
    "        doc2vecs.append(doc2vec.infer_vector(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = []\n",
    "\n",
    "for q in questions:\n",
    "    vec = [model.wv[w] for w in q.split() if w in model.wv]\n",
    "    if len(vec) < 1:\n",
    "        word2vec.append(np.zeros(300))\n",
    "    else:\n",
    "        word2vec.append(np.array(np.mean(vec,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enthropy = []\n",
    "for q in questions:\n",
    "    question = q.split()\n",
    "    q_dic = Counter(question)\n",
    "    q_len = len(question)\n",
    "    vector = []\n",
    "    cnt=0\n",
    "    for w in vectorizer.get_feature_names():\n",
    "            if w in question:\n",
    "                vector.append(q_dic[w]/q_len*np.log2(q_dic[w]/q_len))\n",
    "            else:\n",
    "                vector.append(-0.00001)\n",
    "            cnt=cnt+1\n",
    "    enthropy.append(vector.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=200,algorithm='arpack')\n",
    "matr = svd.fit_transform(np.array(enthropy).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = Normalizer().fit_transform(matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enth = {}\n",
    "for i in list(zip(vectorizer.get_feature_names(),matr)):\n",
    "    enth[i[0]]=[i[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for q in questions:\n",
    "    vec = [enth[w][0] for w in q.split() if w in list(enth.keys())]\n",
    "    if len(vec) < 1:\n",
    "        embeddings.append(np.zeros(200))\n",
    "    else:\n",
    "        embeddings.append(np.array(np.mean(vec,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 748)\n"
     ]
    }
   ],
   "source": [
    "count_model = CountVectorizer(min_df=3,ngram_range=(1,1))\n",
    "X_ = count_model.fit_transform(questions)\n",
    "Xc = (X_.T * X_)\n",
    "Xc.setdiag(0)\n",
    "co_occur = Normalizer().fit_transform(Xc.todense())\n",
    "print(Xc.todense().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word2vec).to_csv(\"word2vec.tsv\", sep='\\t',index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "абитуриент зелёный\n",
      "адрес корочка\n",
      "адрес отправлять\n",
      "адрес письмо\n",
      "адрес посылать\n",
      "адрес точный\n",
      "адрес эл\n",
      "английский иностранный\n",
      "английский интересовать\n",
      "английский язык\n",
      "анкета заполнить\n",
      "анкета ксерокопия\n",
      "анкета серия\n",
      "анкета страница\n",
      "армия действительный\n",
      "армия летом\n",
      "армия осень\n",
      "армия отсрочка\n",
      "армия пойти\n",
      "армия призыв\n",
      "армия сын\n",
      "асу заочко\n",
      "асу нгд\n",
      "асу расписание\n",
      "асу ускоренный\n",
      "аудитория заочник\n",
      "аудитория предоставлять\n",
      "аудитория присутствовать\n",
      "аудитория сколька\n",
      "аэрокосмический одновременно\n",
      "база вместо\n",
      "база проживать\n",
      "бакалавр кафедра\n",
      "безопасность горный\n",
      "безопасность информационный\n",
      "безопасность система\n",
      "билет собрание\n",
      "билет студенческий\n",
      "большой маленький\n",
      "будущее комплекс\n",
      "будущее олимпиада\n",
      "бф пнипа\n",
      "бюджетник социальный\n",
      "бюджетник стипендия\n",
      "бюджетник студенческий\n",
      "вакантный равный\n",
      "взять отпуск\n",
      "вид почта\n",
      "вид эл\n",
      "вид электронный\n",
      "видеть выложить\n",
      "внутренний действительный\n",
      "военкомат новый\n",
      "военный кафедра\n",
      "военный служба\n",
      "восстановиться гнф\n",
      "восстановиться осень\n",
      "восстановиться очно\n",
      "восстановиться перейти\n",
      "временной жильё\n",
      "временной карта\n",
      "временной новый\n",
      "временной предоставление\n",
      "временной регистрация\n",
      "временной согласиться\n",
      "выделить зелёный\n",
      "выделить понимать\n",
      "выделить правильно\n",
      "выйти выложить\n",
      "выйти размер\n",
      "выйти сначала\n",
      "выложить гнф\n",
      "высылать посылать\n",
      "высылать эл\n",
      "главное занятие\n",
      "главное комплекс\n",
      "главное корпус\n",
      "главное мтф\n",
      "главное пара\n",
      "главное стоять\n",
      "гнф заочно\n",
      "гнф нгд\n",
      "гнф нефтяной\n",
      "гнф очно\n",
      "гнф стоимость\n",
      "говорить зелёный\n",
      "горный нефтяной\n",
      "гражданин призыв\n",
      "граф заполнить\n",
      "граф номер\n",
      "губернаторский социальный\n",
      "губернаторский стипендия\n",
      "гуманитарный инновация\n",
      "гуманитарный экономика\n",
      "гумф заключить\n",
      "гумф оплатить\n",
      "гумф экономика\n",
      "далее корочка\n",
      "далее фото\n",
      "дальнейший действие\n",
      "дверь открытый\n",
      "действие явиться\n",
      "действительный летом\n",
      "действительный минимальный\n",
      "действительный призыв\n",
      "действительный сын\n",
      "договор заключить\n",
      "документ заявление\n",
      "донести инна\n",
      "донести медицинский\n",
      "донести остальной\n",
      "донести присутствовать\n",
      "донести справка\n",
      "донести фото\n",
      "дополнительно медицинский\n",
      "дополнительно предоставлять\n",
      "дополнительно фотография\n",
      "достаточно сертификат\n",
      "ехать заселиться\n",
      "ехать прийтись\n",
      "ехать проживание\n",
      "жильё жить\n",
      "жильё общежитие\n",
      "жильё предоставление\n",
      "жильё проблема\n",
      "жильё проживать\n",
      "жильё регистрация\n",
      "жильё согласиться\n",
      "жить зеленоград\n",
      "жить комната\n",
      "заверять ксерокопия\n",
      "заверять нести\n",
      "заверять отправлять\n",
      "заверять посылать\n",
      "заключить оплатить\n",
      "заключить подписать\n",
      "закончить учиться\n",
      "занятие заочник\n",
      "занятие комплекс\n",
      "занятие корпус\n",
      "занятие мтф\n",
      "занятие начинаться\n",
      "занятие пара\n",
      "занятие первокурсник\n",
      "занятие собрание\n",
      "заочник начинаться\n",
      "заочник первокурсник\n",
      "заочник собрание\n",
      "заочно нефтяной\n",
      "заочно очно\n",
      "заочный очно\n",
      "заочный очный\n",
      "заплатить оплачивать\n",
      "заполнить заполнять\n",
      "заполнить ксерокопия\n",
      "заполнить распечатать\n",
      "заполнить регистрационный\n",
      "заполнить сертификат\n",
      "заполнить страница\n",
      "заполнить эл\n",
      "заполнять распечатать\n",
      "заселение заселиться\n",
      "заселение первокурсник\n",
      "заселение собрание\n",
      "заявка эл\n",
      "зеленоград москва\n",
      "зеленоград регистрация\n",
      "зелёный нести\n",
      "зелёный означать\n",
      "зелёный понимать\n",
      "зелёный правильно\n",
      "извинить равно\n",
      "иметься мёд\n",
      "инна нести\n",
      "инна остальной\n",
      "инна подойти\n",
      "инна поздний\n",
      "инна справка\n",
      "инна фото\n",
      "инновация менеджмент\n",
      "инновация область\n",
      "инновация профессия\n",
      "инновация профиль\n",
      "инновация раздел\n",
      "инновация экономика\n",
      "иностранный интересовать\n",
      "иностранный яз\n",
      "иностранный язык\n",
      "информатика прикладной\n",
      "информатика техника\n",
      "информатика электроника\n",
      "информационный система\n",
      "информационный технология\n",
      "иняз таблица\n",
      "искать междисциплинарный\n",
      "испытание экзамен\n",
      "кабинет подойти\n",
      "кафедра пример\n",
      "кафедра служба\n",
      "кафедра счёт\n",
      "класс политех\n",
      "кома обратиться\n",
      "комната пара\n",
      "комната ребёнок\n",
      "комплекс корпус\n",
      "комплекс олимпиада\n",
      "комплекс пара\n",
      "комплекс реквизит\n",
      "конец ситуация\n",
      "контракт набрать\n",
      "корочка ксерокопия\n",
      "корочка отправлять\n",
      "корочка посылать\n",
      "корочка почта\n",
      "корочка эл\n",
      "корпус проживание\n",
      "ксерокопия отправлять\n",
      "ксерокопия паспорт\n",
      "ксерокопия посылать\n",
      "ксерокопия почта\n",
      "ксерокопия свидетельство\n",
      "ксерокопия фамилия\n",
      "ксерокопия эл\n",
      "курс сессия\n",
      "летом осень\n",
      "лично присутствовать\n",
      "льгота нея\n",
      "математик математика\n",
      "математик физика\n",
      "математика обществознание\n",
      "математика физик\n",
      "математика физика\n",
      "математика яз\n",
      "математика язык\n",
      "медицинский фото\n",
      "месяц оплачивать\n",
      "минимальный проходная\n",
      "мп тк\n",
      "мпитк экт\n",
      "начать согласиться\n",
      "неделя стоять\n",
      "некоторый равный\n",
      "некоторый рейтинг\n",
      "необходимый страница\n",
      "нести остальной\n",
      "номер серия\n",
      "номер сертификат\n",
      "область профессия\n",
      "область раздел\n",
      "обновляться пора\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-044b2f602c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n\u001b[0;32m--> 963\u001b[0;31m                                      key=itemgetter(1))]\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "for i in range(matr.shape[0]):\n",
    "    for j in range(matr.shape[0]):\n",
    "        if i!=j and vectorizer.get_feature_names()[i] in model.wv and vectorizer.get_feature_names()[j] in model.wv:\n",
    "            if cosine_similarity([model.wv[vectorizer.get_feature_names()[i]]],[model.wv[vectorizer.get_feature_names()[j]]]) > 0.5:\n",
    "                if str(i)+' '+str(j) not in pairs and str(j)+' '+str(i) not in pairs:\n",
    "                    pairs.append(str(i)+' '+str(j))\n",
    "                    mean = np.mean(np.mean([matr[i],matr[j]],axis=0))\n",
    "                    matr[i] = mean\n",
    "                    matr[j] = mean\n",
    "                    print(vectorizer.get_feature_names()[i],vectorizer.get_feature_names()[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
