{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns =100\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from Common import preprocessing,evaluation,CosineClassifier as cos\n",
    "classes_map = {'DOC':0, 'ENTER':1, 'ORG':2, 'PRIV':3, 'RANG':4, 'HOST':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..//Data//data.txt', delimiter=';', engine='python',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.array(df.question)\n",
    "questions = preprocessing.preprocess_list(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3,ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(df['class'])\n",
    "y = list(map(lambda x: classes_map[x],classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.33, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = OneVsRestClassifier(LogisticRegression(random_state=0,C=10,solver='lbfgs',)).fit(X_train, y_train)\n",
    "ridge = OneVsRestClassifier(RidgeClassifier(random_state=0)).fit(X_train, y_train)\n",
    "svc = OneVsRestClassifier(LinearSVC(random_state=0,)).fit(X_train, y_train)\n",
    "#clf = cos.CosineClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6800271059673625\n",
      "0.6630760215261825\n",
      "0.6734072189098693\n"
     ]
    }
   ],
   "source": [
    "print(evaluation.get_CV_scores(log_reg,X_test,y_test,'f1_weighted').mean())\n",
    "print(evaluation.get_CV_scores(ridge,X_test,y_test,'f1_weighted').mean())\n",
    "print(evaluation.get_CV_scores(svc,X_test,y_test,'f1_weighted').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (question,model):\n",
    "    question = preprocessing.preprocess_list([question])[0]\n",
    "    vect = vectorizer.transform([question])\n",
    "    return model.predict_proba(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 752)\n"
     ]
    }
   ],
   "source": [
    "count_model = CountVectorizer(min_df=3,ngram_range=(1,1))\n",
    "X = count_model.fit_transform(questions)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)\n",
    "print(Xc.todense().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co_occur = pd.DataFrame(Xc.todense(),columns=count_model.get_feature_names())\n",
    "df_co_occur.index = count_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_docs = {}\n",
    "for i in range(Xc.todense().shape[0]):\n",
    "    words = []\n",
    "    for j in range(Xc.todense().shape[1]):\n",
    "        weight = Xc.todense()[i,j]\n",
    "        if weight > 1:\n",
    "            words = words + ([count_model.get_feature_names()[j]]*weight)\n",
    "    pseudo_docs[count_model.get_feature_names()[i]] = words.copy()\n",
    "    words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1582866, 2745800)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec([q.split() for q in questions], size=300, window=10,)\n",
    "model.train([q.split() for q in questions],epochs=200,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_docs_vec = {}\n",
    "for word in pseudo_docs.keys():\n",
    "    vec = (np.mean([model.wv[w] for w in pseudo_docs[word] if w in model.wv],axis=0))\n",
    "    if not np.isnan(vec).any():\n",
    "        pseudo_docs_vec[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "cnt = 0\n",
    "for q in questions:\n",
    "    vec = [pseudo_docs_vec[w] for w in q.split() if w in list(pseudo_docs_vec.keys())]#*tfidf\n",
    "    if len(vec) < 1:\n",
    "        embeddings.append(np.zeros(300))\n",
    "    else:\n",
    "        embeddings.append(np.array(np.mean(vec,axis=0)))\n",
    "    cnt = cnt +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_embeddings = []\n",
    "cnt = 0\n",
    "for q in questions:\n",
    "    vec = [model.wv[w]*tfidf[cnt][w] if w in list(tfidf[cnt]) else model.wv[w]*0 for w in q.split() if w in model.wv]\n",
    "    #vec = [model.wv[w] for w in q.split() if w in model.wv]\n",
    "    if len(vec) < 1:\n",
    "        def_embeddings.append(np.zeros(300))\n",
    "    else:\n",
    "        def_embeddings.append(np.array(np.mean(vec,axis=0)))\n",
    "    cnt=cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = []\n",
    "for i in range(X.shape[0]):\n",
    "    dictionary = {}\n",
    "    for j in range(len(vectorizer.get_feature_names())):\n",
    "        dictionary[vectorizer.get_feature_names()[j]] = X[i,j]\n",
    "    tfidf.append(dictionary.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
